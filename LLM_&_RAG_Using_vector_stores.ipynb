{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHI0+bUU7g8Hxjub6Dig42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raviakasapu/LLM-Training-Docs/blob/main/LLM_%26_RAG_Using_vector_stores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augumented Generation (RAG)\n",
        "\n",
        "## and Evaluation"
      ],
      "metadata": {
        "id": "E5D8efMf2q7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade langchain\n",
        "#!pip install python-dotenv\n",
        "#!pip install openai"
      ],
      "metadata": {
        "id": "tVxvI8I8N-xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain[docarray]\n",
        "#!pip install tiktoken"
      ],
      "metadata": {
        "id": "-D9oD5pnOXEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pdf2image\n",
        "#!pip install unstructured\n",
        "#!pip install pdfminer\n",
        "#!pip install pdfminer.six"
      ],
      "metadata": {
        "id": "6EIxn8mSO7f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import Openai and input your API key"
      ],
      "metadata": {
        "id": "YD0lxgZWKvsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "#paid key\n",
        "#os.environ[\"OPENAI_API_KEY\"]=<your api key>"
      ],
      "metadata": {
        "id": "Sgsj-EC9NZym"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "MOWqTtYFNZ1h"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we will be using `gpt-3.5-turbo-0301` model"
      ],
      "metadata": {
        "id": "SG1huOSzK09y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gpt-3.5-turbo-0301\""
      ],
      "metadata": {
        "id": "OGC06YJrNZ4q"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "eU2L0xKpNZ7i"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "import tiktoken\n",
        "import pdf2image\n",
        "import pdfminer\n",
        "import pdfminer.high_level"
      ],
      "metadata": {
        "id": "KYYadaJRNZ-I"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "omE9jD4GQnD6"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We will be using information with regard to Microsoft Fabric which is released in 2023. OpenAi chat model does not have information regarding Microsoft Fabric and we will depend on the the document to answer the questions"
      ],
      "metadata": {
        "id": "Se-YQnpXK87_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_url = \"https://learn.microsoft.com/pdf?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Ffabric%2Fget-started%2Ftoc.json\"\n",
        "!wget --no-cache --backups=1 {pdf_url} --output-document=microsoft_fabric.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f4fAO6nOjZR",
        "outputId": "ed2a9e95-f9e9-42b9-b891-52e3ab8375e5"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-12 01:35:03--  https://learn.microsoft.com/pdf?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Ffabric%2Fget-started%2Ftoc.json\n",
            "Resolving learn.microsoft.com (learn.microsoft.com)... 104.85.2.139, 2a02:26f0:b200:18c::3544, 2a02:26f0:b200:18d::3544\n",
            "Connecting to learn.microsoft.com (learn.microsoft.com)|104.85.2.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8488195 (8.1M) [application/pdf]\n",
            "Saving to: ‘microsoft_fabric.pdf’\n",
            "\n",
            "microsoft_fabric.pd 100%[===================>]   8.09M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-09-12 01:35:06 (113 MB/s) - ‘microsoft_fabric.pdf’ saved [8488195/8488195]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1"
      ],
      "metadata": {
        "id": "on-BOW1iMksh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### using `UnstructuredPDFLoader`"
      ],
      "metadata": {
        "id": "QU5ga2fEMqTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredPDFLoader(\"microsoft_fabric.pdf\", mode=\"elements\")"
      ],
      "metadata": {
        "id": "DJsfavaiOq2L"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "G1B3pYyTOsh9"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTl1DoUbRvat",
        "outputId": "d391d612-ec45-4113-d40d-70d9f129bff3"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='repositories into actionable workloads and analytics, and is an implementation of data', metadata={'source': 'microsoft_fabric.pdf', 'coordinates': {'points': ((64.0000009173332, 661.7616724113459), (64.0000009173332, 673.7616726793458), (518.5761906695336, 673.7616726793458), (518.5761906695336, 661.7616724113459)), 'system': 'PixelSpace', 'layout_width': 594.95996, 'layout_height': 841.91998}, 'filename': 'microsoft_fabric.pdf', 'last_modified': '2023-09-07T18:46:04', 'filetype': 'application/pdf', 'page_number': 5, 'category': 'NarrativeText'})"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=DocArrayInMemorySearch,\n",
        "    embedding=embeddings\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "id": "6zTHMeMmOuVr"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=index.vectorstore.as_retriever(),\n",
        "    verbose=True,\n",
        "    chain_type_kwargs = {\n",
        "        \"document_separator\": \"<<<<>>>>>\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "jGELjSaQRLPk"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =\"what are the components of microsoft fabric\""
      ],
      "metadata": {
        "id": "xozqVxL2RelD"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = index.query(query)\n",
        "display(Markdown(response2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "r6jN3xZmRlt0",
        "outputId": "b348b9c8-62b1-4973-ed56-b830be1b13b6"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " Microsoft Fabric is a distributed systems platform that provides a set of tools and services for developing, deploying, and managing applications and services. The components of Microsoft Fabric include Service Fabric, Event Hubs, Azure Cosmos DB, Azure SQL Database, Azure Storage, and Azure Service Bus."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ooEyHKbkRkNv",
        "outputId": "0f5f5363-90be-4827-d264-666467979272"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Microsoft Fabric is a distributed systems platform that provides a set of tools and services for building scalable and reliable applications. Some of the components of Microsoft Fabric include stateful and stateless services, reliable collections, actors, and partitions. It also includes tools for managing and monitoring applications running on the platform.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 =\"what kind of connectors can Microsoft Fabric can support\""
      ],
      "metadata": {
        "id": "V5GV680mulN5"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = index.query(query2)\n",
        "display(Markdown(response2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "uLD8dpQWuw14",
        "outputId": "2a42a187-2211-4342-8c3d-77de4ccbcc31"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " I don't know."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"Is it a data lake?\""
      ],
      "metadata": {
        "id": "P2kgPIVUwFzT"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response3 = index.query(query3)\n",
        "display(Markdown(response3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "GtBuyl_dwILJ",
        "outputId": "91ef6f6e-e9c3-44a2-bb59-708d209cfa76"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " No, it is a data warehouse."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2"
      ],
      "metadata": {
        "id": "dTMvgD47NIGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### using package `pypdf`"
      ],
      "metadata": {
        "id": "mI2LjfRAR9D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pypdf\n",
        "#!pip install chromadb\n"
      ],
      "metadata": {
        "id": "CW65x34sR4gg"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader # for loading the pdf\n",
        "from langchain.embeddings import OpenAIEmbeddings # for creating embeddings\n",
        "from langchain.vectorstores import Chroma # for the vectorization part\n",
        "from langchain.chains import ChatVectorDBChain # for chatting with the pdf\n",
        "from langchain.llms import OpenAI # the LLM model we'll use (CHatGPT)"
      ],
      "metadata": {
        "id": "YWvrKLQNR72u"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "import chromadb\n",
        "import chromadb.config\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "GPt7cCrKSIhL"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"microsoft_fabric.pdf\"\n",
        "loader2 = PyPDFLoader(pdf_path)\n",
        "pages = loader2.load_and_split()\n",
        "print(pages[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLI_GJ2rSOdd",
        "outputId": "9e70bd6d-9b5d-4b3c-fba4-e730e9f7837a"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell us about y our PDF experience.\n",
            "Microsoft Fabric get star ted\n",
            "documentation\n",
            "Microsoft F abric is a unified platform that can meet your organization's data and\n",
            "analytics needs. Discover the F abric shared and platform documentation from this page.\n",
            "About Micr osoft Fabric\n",
            "ｅOVERVIE W\n",
            "What is F abric?\n",
            "Fabric terminology\n",
            "What's New\n",
            "ｂGET STARTED\n",
            "Start a F abric trial\n",
            "Fabric home navigation\n",
            "End-to-end tutorials\n",
            "Context sensitive Help pane\n",
            "Get star ted with F abric it ems\n",
            "ｐCONCEPT\n",
            "Find items in OneLake data hub\n",
            "Promote and certify items\n",
            "ｃHOW-T O GUIDE\n",
            "Apply sensitivity labels\n",
            "Worksp aces\n",
            "ｐCONCEPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb2 = Chroma.from_documents(pages, embedding=embeddings,\n",
        "                                 persist_directory=\".\")\n",
        "vectordb2.persist()"
      ],
      "metadata": {
        "id": "ogU1d2acSS8M"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_qa = ChatVectorDBChain.from_llm(\n",
        "    OpenAI(temperature=0,\n",
        "           model_name=llm_model\n",
        "           ),\n",
        "    vectordb2,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "result = pdf_qa({\"question\": query, \"chat_history\": \"\"})\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOGgrkEISXtv",
        "outputId": "2631d867-77d3-4e99-a19b-8870dfed79c2"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The components of Microsoft Fabric include Data Engineering, Data Factory, Data Science, Data Warehouse, Real-Time Analytics, and Power BI, all integrated into a shared SaaS foundation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pdf_qa({\"question\": query2, \"chat_history\": \"\"})\n",
        "print(\"Answer:\")\n",
        "print(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pobHZ0vru3zz",
        "outputId": "8f588adc-560a-4972-93a0-7dc4eec1b4ad"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "The given context does not provide information on what kind of connectors Microsoft Fabric can support.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"Is it a data lake?\"\n",
        "result = pdf_qa({\"question\": query3, \"chat_history\": \"\"})\n",
        "print(\"Answer:\")\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAe1NJWJv7Ur",
        "outputId": "0f9d26eb-fb96-4022-d44c-9efd45fa094b"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "Yes, OneLake is a data lake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluation"
      ],
      "metadata": {
        "id": "AnYe3QzVwQcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.qa import QAGenerateChain\n",
        "from langchain.evaluation.qa import QAEvalChain"
      ],
      "metadata": {
        "id": "ugGmtWOSwPxB"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))"
      ],
      "metadata": {
        "id": "AMNP2qPKwUaK"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_examples = example_gen_chain.apply_and_parse(\n",
        "    [{\"doc\": t} for t in pages[:5]]\n",
        ")"
      ],
      "metadata": {
        "id": "KJFLXIF_wUx3"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJPwfwW1yVL7",
        "outputId": "f8aad748-f15f-4374-9362-e78c3f273c2d"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'qa_pairs': {'query': 'What is Microsoft Fabric?',\n",
              "   'answer': \"Microsoft Fabric is a unified platform that can meet an organization's data and analytics needs.\"}},\n",
              " {'qa_pairs': {'query': 'What are the four sections listed in the document?',\n",
              "   'answer': 'The four sections listed in the document are Fabric workspace, Workspace roles, Get started, and Workspace access control.'}},\n",
              " {'qa_pairs': {'query': 'What is Microsoft Fabric and what services does it offer?',\n",
              "   'answer': 'Microsoft Fabric is an all-in-one analytics solution that offers a comprehensive suite of services, including data lake, data engineering, and data integration. It covers everything from data movement to data science, real-time analytics, and business intelligence. Microsoft Fabric brings together new and existing components from Power BI, Azure Synapse, and Azure Data Factory into a single integrated environment. These components are then presented in various customized user experiences.'}},\n",
              " {'qa_pairs': {'query': 'What is the benefit of using Microsoft Fabric SaaS experience?',\n",
              "   'answer': 'The benefit of using Microsoft Fabric SaaS experience is that all the data and services are seamlessly integrated, allowing IT teams to centrally configure core enterprise capabilities and permissions that are automatically applied across all the underlying services. Additionally, data sensitivity labels are inherited automatically across the items in the suite, freeing creators from the need to integrate, manage, or understand the underlying infrastructure that supports the experience.'}},\n",
              " {'qa_pairs': {'query': 'What is the purpose of Real-Time Analytics in Fabric?',\n",
              "   'answer': 'Real-Time Analytics in Fabric is the best-in-class engine for observational data analytics, which is often semi-structured in formats like JSON or Text and comes in at high volume with shifting schemas. This data is hard for traditional data warehousing platforms to work with, but Real-Time Analytics is designed specifically to handle this type of data.'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain debug\n",
        "\n",
        "* the debug flag will be used to geenrate detailed output from LLM model, which can further used to analyse the Context, Prompt and response\n",
        "\n",
        "* we can further improve the answers by understanding the providing more context to the LLM"
      ],
      "metadata": {
        "id": "fKJFVL3kOBZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "nJwCCcYUDcri"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "examples = []\n",
        "for i in range(len(new_examples)):\n",
        "  print(new_examples[i]['qa_pairs']['query'])\n",
        "  examples.append(\n",
        "      {'query':new_examples[i]['qa_pairs']['query'],\n",
        "       'answer':new_examples[i]['qa_pairs']['answer']\n",
        "       }\n",
        "  )\n",
        "  pred = pdf_qa({\"question\": new_examples[i]['qa_pairs']['query'], \"chat_history\": \"\"})\n",
        "  predictions.append(\n",
        "    {'question': pred['question'],\n",
        "     'result':pred['answer']\n",
        "    }\n",
        "  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc-6THDZ4BQD",
        "outputId": "0962c755-eb16-4101-b8cb-318357bdbaa4"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is Microsoft Fabric?\n",
            "What are the four sections listed in the document?\n",
            "What is Microsoft Fabric and what services does it offer?\n",
            "What is the benefit of using Microsoft Fabric SaaS experience?\n",
            "What is the purpose of Real-Time Analytics in Fabric?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Q5kQ1N_v03",
        "outputId": "fea8f394-0d4c-48a5-e31f-805ca68feee1"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What is the purpose of Real-Time Analytics in Fabric?',\n",
              " 'answer': 'Real-Time Analytics in Fabric is the best-in-class engine for observational data analytics, which is often semi-structured in formats like JSON or Text and comes in at high volume with shifting schemas. This data is hard for traditional data warehousing platforms to work with, but Real-Time Analytics is designed specifically to handle this type of data.'}"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2PEu_XAGuJs",
        "outputId": "a35e69b3-b528-4fd1-d428-06a186ead367"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is the purpose of Real-Time Analytics in Fabric?',\n",
              " 'result': 'The purpose of Real-Time Analytics in Fabric is to provide an end-to-end analytics solution for enterprises that covers everything from data movement to data science, business intelligence, and real-time analytics. It is one of the experiences tailored to a specific persona and task in the comprehensive set of analytics experiences offered by Microsoft Fabric.'}"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_chain = QAEvalChain.from_llm(llm)"
      ],
      "metadata": {
        "id": "uIjsDA2wwU4P"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs = eval_chain.evaluate(examples, predictions)"
      ],
      "metadata": {
        "id": "uRex8BWG-oSk"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "#### the results are available in graded_outputs and can further used to debug the responses"
      ],
      "metadata": {
        "id": "8X536z3JNN6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g813NePNHYf_",
        "outputId": "5092543b-1c96-4d9f-b0a6-418390e1cc28"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'results': 'CORRECT'},\n",
              " {'results': 'INCORRECT'},\n",
              " {'results': 'CORRECT'},\n",
              " {'results': 'CORRECT'},\n",
              " {'results': 'INCORRECT'}]"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    }
  ]
}